---
title: "BDPG paper skeleton"
author: "Bill Langford"
date: "`r Sys.Date()`"
output:
  pdf_document:
    fig_caption: yes
    number_sections: yes
    toc: yes
    toc_depth: 4
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '4'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

#  Abstract

#  Introduction

##  Reserve selection commonly used but without any measured estimates of solution quality under uncertainty
- Optimizer performance is only guaranteed under data without uncertainty.
- But there's a lot of uncertainty in inputs
- Also, variation in problem difficulty
- Some attempts to address this, but no generally test and predict performance under uncertainty
- While reserve selection is intended as a decision aid rather than a decision-making device, the tacit assumption is that the solutions offered have at least reasonable quality, but this has never been evaluated.


##  Can't predict how reliable specific RS is on specific problem   
- Toy problems
    - Little complexity
    - No acknowledgement or consideration of variability in problem difficulty
- Currently no work looking at even *mean* performance and variability under uncertainty across multiple problems
- Absolutely no work on predicting error for arbitrary *specific* problems

## Prediction requires several things that are missing now
- Lots of training data with known solutions and error characteristics
    - Training data has to represent the range of problems in the universe to be generalized over
    - Need to generate many problems of varying difficulty with known solutions
        - Difficulties generating problems with known solutions
            - Currently can't predictably vary problem difficulty
            - Can run ILP like Gurobi but too slow for large numbers of problems
- Measurable attributes of problems
    - Currently only know # of spp and # of PUs
    - Need other measures that *can* be known
    - Might assume that input error amount/type are known, but ...

##  Here, we describe a method for learning to predict the amount of output error
- Generating problems of varying difficulty with known solutions
- New input features for predicting problem difficulty



To our knowledge, this work is novel in 1) raising the question of the relative difficulty of different reserve selection problems, 2) mapping methods from the theory of computation for generating reserve selection problems with known difficulty and known solutions, 3) extending those methods to allow more ecologically realistic species distributions, 4) attempting to predict output error of specific reserve selectors on specific reserve selection problems, 5) identifying bipartite network complexity measures useful in predicting reserve selection output error, and 6) attempting to predict the amount of error in reserve selector output for specific given problems.  While this is only a first step in being able to predict the accuracy of particular reserve selectors on particular reserve selection problems in general, it is a significant step in showing its importance and possibility



#  Methods

## Background

A simplest form of the reserve selection problem is the following: given a set of species occurrences on a set of patches, find the smallest subset of the patches that contains at least one occurrence of each species.  In more general forms of the problem, 1) "species" could be any conservation feature, 2) "patches" are often referred to as planning units, 3) occurrence targets for features could have values other than one, 4) planning units could have unequal costs, and 5) there could be other constraints on the solution such as minimizing total boundary length.  Here, we will only consider the simple form because it facilitates generating problems with known solutions and it's already complex enough to cause reserve selectors substantial difficulties.  Future work will consider more complex problems.

The simple form of reserve selection is related to a problem known in theory of computation as Minimum Set Cover, which belongs to a heavily-studied class of difficult problems known as NP-Complete or NP-Hard depending on the exact phrasing of each problem.  The exact definitions of these complexity classes and their details are not necessary for understanding the methods presented here and can be found in any text on theory of computation or algorithm design.  However, the study of those classes has led to two things important to the work described here.  First, certain problems have a form of equivalance, in that given elements of one problem, we can find corresponding elements in another kind of problem and the solution there can be mapped back as a solution of the original problem.  Second, the large variation in difficulty among specific instances of each problem type has led to work on predicting relative problem difficulty and generating problems of differing difficulties with known solutions.  

One technique for generating difficult problems is "solution hiding".  There, a problem is generated in a way that has an obvious solution, then, obfuscating elements are added to the problem in a way that they don't change the solution but they make searching for it difficult.  As a simple analogy, suppose there was a 10,000 hectare forest of nothing but pine trees, except for three rose bushes and the "problem" was to find the three bushes.  If the problem generator started with an empty landscape, planted the three bushes at locations they knew and then planted the pine forest afterwards, the generator would easily know the solution but make it difficult for the searcher to find.  

Xu et al.[xxx] describes a solution-hiding algorithm for generating instances of a well-known problem called Satisfiability.  Importantly, they also provide theoretical predictions of the relative difficulty of each problem based on the constructor's parameters.  Elsewhere [xxx], Xu briefly describes a variation of the generator that is extremely simple and generates instances with known solutions for a difficult graph problem called Maximum Independent Set.  This is the first step in mapping from problem to problem to find a way to generate reserve selection problems of known difficulty with known solutions.  We give more details below, but the basic idea is that the solution of the Maximum Independent Set problem is known to be the complement of the solution to another graph problem called Minimum Vertex Cover.  Minimum Vertex Cover is in turn, a special case of the Minimum Set Cover problem, which brings us back to reserve selection.  Consequently, we have a very simple algorithm for generating reserve selection problems of varying difficulty and known solutions.

There are two major drawbacks to problems generated with the XXXX method.  First, it only generates problems where *every* species in *every* problem occurs on *exactly* 2 patches.  Since this is ecologically unrealistic, we modified the XXXX method to allow the wrapping of nearly any species distribution around XXXX problems while preserving the known optimal solution.  The second ecologically unrealistic attribute of these problems is that there is no error or uncertainty in the occurrence and cost data.  Consequently, we built a series of simple models of false positive and false negative input errors and cost errors and applied them to the data.   

All of this gives us the skeleton for generating non-trivial reserve selection problems with known solutions and approximately known difficulty so that we can properly evaluate the performance of different reserve selectors.  However, what we would really like to know is, given a particular reserve selection problem and reserve selector, can we predict how much error is likely in the specific solution to this specific problem?  By error, we mean two things: 1) How much does it fall short of its representation targets? and 2) How much more does it cost than the correct optimal solution?  

To answer these questions for specific problems, we need to identify descriptors for each problem that are knowable or measurable without knowing the correct solution.  To our knowledge, the only descriptors people might currently use to guess the likely performance of a reserve selector would be related to the number of species and/or the number of patches.  We show here that, in our experiments, these are virtually useless as predictors of problem difficulty.  Instead, we reframe the problem as a bipartite network of species and patches, analogous to networks used in studying plant-pollinator interactions.  We then compute network metrics related to the relative complexity of these networks and show their utility in our experiments for predicting output errors in representation and cost.  

## Problem set generation

In this section, we give an overview of the structure and number of experiments.  Details of each component are given in later sections.  For this paper, we generated a set of problems that we could use to do initial explorations of the data as well as test the code under a fairly large number of conditions.  Later papers will formally define universes of problems and sample from those universes to learn and attempt to generalize over them using the methods developed in this paper.  

We developed problems with known correct answers in blocks of 20 problems, where each of the 20 is derived from a single base problem by adding specific complexities and uncertainties (described below).  We then repeated stochastic variants of the block generation procedure 100 times for each of 5 different input error levels and 2 different problem difficulty levels. This led to the generation of 20 * 100 * 5 * 2 = 20,000 different reserve selection problems.  For each problem, we then applied 9 different reserve selection methods.  

Each block of 20 problems began with:

- 1 Base problem generated using the XXXX method and no input error
- 1 Wrapped problem derived from the Base problem and no input error

These are referred to as the correct or COR problems.

For each of those problems, we created 9 new variations using different combinations of input errors at a single specified rate:

- Cost error only
- Each of the 4 below with and without cost error for a total of 8 variants
    - False negatives only
    - False positives only
    - Both false negative and false positive at the given error rate
    - Both false negative and false positive with error counts matched
    
These are referred to as the apparent or APP problems since they are the data that would be apparent to the user in a real situation where the correct data is unknown.

## Individual problem generation

Generating individual problems relies on the idea of the *maximum independent set*.  In a network, an independent set is any set of nodes where none of those nodes are connected to any other nodes *in that set*.  The *maximum* independent set for a network is defined to be the largest such set possible for that network.  

###  XXXX base problem generation

We generated each base problem by generating a Maximum Independent Set problem with a known optimal solution using the methods given in [XuPaper][XuWebsite].  We then mapped the network into a corresponding reserve selection problem and used the complement of the independent set solution as the optimal solution to the reserve selection problem.  The mapping is as follows:

- Each node in the network corresponds to a unique patch.
- Each link corresponds to a unique species.  
    - That species is designated as occurring in each of the two patches connected by the link.
- Every node/patch NOT in the independent set is included in the optimal solution to the reserve selection problem.

####  Base network generation procedure

The basic idea was to build a set of identical groups of nodes whose structure forced exactly one element of each group to be the independent set for that group.  That way, when we combined the groups, the maximum independent set was just the union of the individual independent nodes.  Finally, we added complexity to this network by adding extra links between the groups, excluding the independent nodes so that they are still the maximum independent set for the more complicated network.

- Define a network that is a collection of **g** identically structured groups of nodes and links, where:
    - Each group consists of **k** nodes where each node has a link to every other node in the group.
- Arbitrarily choose one node in each group and designate each as the independent node for that group.
- For a given number of rounds **r**: 
    - Randomly choose a pair of groups
    - For a given number of linkings **s**:
        - Randomly choose a non-independent node in each of the chosen groups and link them.  (Multiple links between the same node pairs are allowed.)

Note that:

- The union of the group independent nodes is the maximum independent set.
- The optimal reserve selection is the set of g * (k - 1) nodes not in the maximum independent set.

####  Parameter choice

The size and relative difficulty of the problem generated is determined by the choice of parameters in the procedure above.  We derived these parameters from 4 parameters in the XXXX method described in [XuPaper].  The parameters there are driven by theoretical considerations to control problem difficulty and are as follows:

- **alpha** ...
- **N** ...
- **r** ...
- **p** ...

For the experiments in this paper, we chose two distinct sets of values that corresponded to what Xu et al had found to generate easy problems and hard problems:

- EASY
    - **alpha** = ...
    - **N** = ...
    - **r** = ...
    - **p** = ...
- HARD
    - **alpha** = ...
    - **N** = ...
    - **r** = ...
    - **p** = ...

Those values were then converted into the values necessary for the procedure above:

- **g** = ...
- **k** = ...
- **r** = ...
- **s** = ...

giving:

- EASY
    - **g** = ...
    - **k** = ...
    - **r** = ...
    - **s** = ...
- HARD
    - **g** = ...
    - **k** = ...
    - **r** = ...
    - **s** = ...

We made one other modification to these values.  Since the solution size is always g \* (k - 1)  and the part of the landscape not in the solution is only g, some algebra shows that the fraction of the landscape included in the solution = 1 - 1/k.  So, as the size of the groups increases, so does the fraction of the landscape included in the solution.  These large fractions are not ecologically realistic as an amount to reserve, so we fixed k = 2 to get the smallest possible size (1/2) for the solution fraction of the landscape for these experiments.  In the future, we would not repeat this choice when the emphasis is on the wrapped problems since we can directly choose a realistic landscape fraction there and this choice of k moves us away from the predictive choices specified in [XuPaper].   

###  Wrapped problem generation

The XXXX method gave us an ecologically unrealistic, completely flat species distribution with exactly 2 occurrences of every species as well as unrealistically large fractions of the landscape to reserve.  To generate more realistic problems, we developed a method for wrapping a base XXXX problem in a larger species distribution and landscape.  

The basic idea for wrapping is to note that any given species abundance distribution will have one section of the curve where it specifies a certain number of species that occur on exactly two patches.  To generate a wrapped problem then, we need to: 

- Search for a curve that has a section that specifies roughly the same number of species that occur on exactly 2 patches as we have in our base XXXX problem and then,
- Add more species that correspond to the rest of the curve and 
- While making sure that:
    - each of the new species has at least one occurrence in the original optimal reserve selection and 
    - none of the original problem's species occurs outside the original problem's set of patches.
    
We will generally also add more patches to the landscape as a way to control what fraction of the total landscape will be taken up by the optimal reserve selection.  

####  Computing number of patches to add

Given a desired solution fraction and an original XXXX problem:

```
    (soln frac) = (soln size) / ((ind set size) + (soln size) + (num extra patches))
        =>
    (num extra patches) = (soln size)/(soln frac) - ((ind set size) + (soln size))
```

#### Species abundance distribution

To our knowledge, there are unfortunately no studies of what species distributions do occur in real reserve selection problems.  While species distributions in general are studied, the choice of which *subset* of the full distribution to include in a reserve selection problem is completely at the discretion of whoever is doing the selection.  Consequently, for our experiments we had to arbitrarily choose what species distribution to use as something more realistic than two occurrences for every species.  A lognormal is one commonly discussed model of species abundance distribution, so we chose that as an example abundance distribution for our experiments.  

####  Spatial distribution of species

Again, to our knowledge, there are no studies of the spatial co-occurence distributions of species in real reserve selection problems.  Given no reason to choose any particular spatial distribution, we randomly assigned new species occurrences to patches, with two caveats:

- No occurrence could be added to any patch in the XXXX problem's independent set.  
    - This is probably slightly stricter than necessary, but is guaranteed not to violate the original solution.
- The first added occurrence for any new species had to go on a patch in the XXXX solution so that the original solution was guaranteed to also be a solution for the wrapped problem.
    - Subsequent occurrence additions for new species were assigned to the extra patches set, though again, this is stricter than necessary.  

####  No singleton species

If any species occurs on just one patch, then that patch must be included in the solution to insure that all species are represented in the solution.  For this reason, we didn't add any species that occurred on just one patch.

####  Fitting abundance distribution parameters

[NOTE:  *Details of the fitting procedures are in gen_lognormal_overlay.R.*]

Given a desired number of species to occur on exactly two patches and a type of distribution to fit (lognormal in this case), the next steps are:

- identify the parameters of the distribution,
- specify a search algorithm to use in fitting, and 
- define an evaluation function to determine the degree of fit.

**Parameters of lognormal**

The lognormal function is:

xxx = ... [*dnorm (log (abundance))*] ...

So, the parameters that need to be found are **meanlog** and **sdlog**.

**Search algorithm**

Any effective search algorithm could be used.  Since we were programming in R, we used R's `optim` function.  This function requires an initial value and an evaluation function.  We used zzz as the initial value.

**Evaluation function**

We defined the evaluation function a) to reward closeness of the lognormal's count of species on exactly two patches and b) to penalize having large numbers of species and large numbers of occurrences.  

mmm = nnn

Because a perfect fit was very unlikely, we also defined: 

- a tolerance allowed for the fit = xxxx 
- a bound on the number of search iterations = yyyy
- an "imperfect wrap" logical flag indicating whether to accept the best fit found even if it was not within the tolerance.

###  Input error generation

We generated 2 basic types of occurrence error (false positive and false negative) and 1 type of cost error (uniform random).  

For **false negative errors** (FP), at each occurrence of a species on a patch, we drew a uniform random number in the interval [0,1] and if that value was less than or equal to the desired, nominal error rate, we changed the occurrence to an absence.  

For **false positive errors** (FN), we considered all absences of all species on all patches and used the same process as above to flip particular absences to presences.

For **cost errors**, we took the true cost of each patch to be 1 and then applied the given error rate as a fraction of 1 to create an interval of [1-rate,1+rate].  We then drew a uniform random number in that interval to be the apparent cost.  We chose this error model because we are unaware of any research specifying a better model to use and we wanted to see what effects *some* kind of cost error might have.

We also generated several combinations of the errors above.  First, we generated a combined error false positives and false negatives.  Second, we generated a "matched" form of that error to take into account the fact that the fraction of occurrences is generally far smaller than the fraction of absences.  In the matched case, we generated the same *number* of false positives as false negatives rather than the same rate.  Finally, we combined cost error with all 4 of the different sole and combined occurrence errors.  As a result, each correct problem had 9 different error models available to it.

Note that the *realized* error rates in the resulting apparent data generally did not exactly match the *nominal* error rate because of the generation method. We chose this realized rate rather than selecting for the exact nominal rate so that we would get a bit more variation in the error rates tested.  Input error rates reported in the Results are the realized values.

## Problem attributes

For each problem, we recorded 2 classes of problem attributes that can be measured by the user in hopes of predicting the relative difficulty and/or error rate for the reserve selector: problem size and bipartite network complexity.  Problem size is simply the number of species and the number of patches.  Measuring network complexity is more involved. For each problem, we converted the problem to a bipartite network and computed a number of network metrics using the R packages `igraph` and `bipartite`.  

####  `bipartite` package measures

For these first exploratory tests, the only measure we computed with the `bipartite` package was *connectance*, however the R package we produced has options to compute many more `bipartite` metrics.

**...  definition of connectance  ...**

####  `igraph` package measures

The most important network metrics we computed were redundancy measures given by Latapy et al. in [Latapy].  **We chose these measures because ...**

**...  definition of redundancy measures  ...**

These measures aren't available in either the `igraph` or `bipartite` packages in R.  The measures are complicated to compute and we relied on an R  implementation on a web page by XXX [xxx].  That implementation had a few errors when we tried to run it, so we modified that code to allow it to run.  The final R code is given in the xxxxx.R source file in the R package built for this paper, `bdpg` [bdpg]. 

##  Problem difficulty and performance measures

We computed 3 different kinds of measures reflecting the relative difficulty of problems and the performance of reserve selectors on them: fractional error in representation and cost, magnification of input error, and reserve selector run time.  

####  Fractional euclidean error

We measured output error as a Euclidean combination of fractional representation shortfall and fractional cost overrun with respect to the optimal value on the correct data:

fracEucError = sqrt (((numSpp - numSppMeetingTarget)/numSpp)^2 + ((cost - optCost)/optCost)^2)

####  Error magnification

We measured error magnification as the ratio of fractional Euclidean output error to realized input error:

errMag = fracEucError / realizedInputError

###  Run-time measures

We measured the run time for each reserve selector using R's `sys.time` function.

##  Reserve selectors

We ran 9 different reserve selection methods on each problem.  The 4 most important ones were gurobi, marxan, marxan summed solution, and a zonation-like greedy reserve selector.  We also ran 5 other simple greedy reserve selectors for comparison and to see whether any of them behaved better under uncertainty than they did on correct data.  

###  Primary reserve selectors

**Gurobi**   

We encoded each reserve selection problem as an integer linear programming problem and attempted to solve it using the  Gurobi linear programming software  Unfortunately, many of the Hard problems were not solved after 12 hours of run time even though most of the Easy problems took less than a minute.  Because this was just an exploratory study and we were running thousands of problems, we decided to limit Gurobi to whatever solution it found within the first 10 minutes.  

**Marxan**   

We ran Marxan on each problem using default settings and the following variable settings:

- xxx = yyy
- ...

**Marxan summed solution**

When regular Marxan runs, it also outputs a ranking of each patch according to the number of solutions the patch occurred in.  We created a solution from this ranked output by adding patches to the solution in descending order until all species were represented.

**Zonation-like backwards**   

Zonation is generally used in situations where the inputs are pixels rather than patches, but the evaluation function it uses in its greedy search is effective and is interesting to consider in terms of its performance under uncertainty.  We wrote an R function using that encodes Zonation's evaluation function and applied it inside a greedy search algorithm, starting from a solution that includes all patches and progressively removing the least valuable patch (according to the evaluation function) at each step.  Zonation normally starts at the outside of a region and works inward, but the problems in this study have no notion of spatial arrangement, so that aspect of Zonation is ignored.  For this reason, we refer to this method as "Zonation-like".  We also call include "backwards" in the name because it doesn't work like normal greedy algorithms that start from nothing and progressively add the next "best" element.  

The evaluation function used was:

**...  Zonation evaluation function  ...**

###  Less important greedy selectors

We also encoded the well-known greedy selection heuristics "Simple Richness" and "Unprotected Richness".  Simple Richness values each patch simply by the number of species that occur on the patch.  Unprotected Richness values each patch by the number of species on the patch that have not yet had their target met in the current solution that is being incrementally built.  

Unlike Zonation, both Simple Richness and Unprotected Richness are typically run in the forward direction.  That is, they build a solution by starting with nothing and then progressively adding the next best patch according to their evaluation function.  Because Zonation works so well using the reverse strategy of starting with everything and progressively removing things, we were curious about running backwards with other greedy heuristics.  Consequently, we encoded both a forward and a backward version of all 3 greedy methods, for a total of 6 greedy methods.  The source code is in the `bdpg` package R source files **... greedy files ...**.

##  Prediction 

###  Values to predict

###  Prediction methods

####  Linear models

####  Regression trees

####  Random forest

##  Running and managing many experiments

###  Number of experiments

###  Tzar

###  Nectar

#  Results

##  Input errors vs. output errors

###  Errors have huge variability regardless of input error amount and type

###  Optimization often amplifies input error

####  Error amplification

####  Error correction

##  Error predictability

###  Problem size is poor predictor

###  Graph measures appear to predict well

#  Discussion

##  Caveats

###  No generalization beyond this data set

Only intended as starting point to test the code and explore general behavior.

However, interesting to look at implications of trying to generalize to Hard problems from Easy data in this experiment, since that's the history of the field.

##  Lit review

###  Future work

####  Need broader random sample within Xu universe to generalize there

Running more experiments now.

####  Need more realistic distributions and problems (e.g., boundary lengths)

Will ask Marxan community for input files since there are lots of them applied to lots of real problems and all use the same common input file format and it's easy to anonymize.

#  Conclusion

##  Contributions
- Mapping of methods from theory of computation into reserve selection for problem generation accounting for
    - varying problem difficulty
    - known solutions
    - scalable generation time
- New method for wrapping Xu problems to make them more realistic for ecology
- Mapping bipartite network attributes into problem difficulty prediction in reserve selection
- Reasonably large first study with both easy and hard problems and tested predictions of error
- Reproducible data and R package code

##  Recommendations
- Test and predict the robustness of methods to uncertainty and problem difficulty
- Make optimization evaluation reflect true goals
    - If we're going to declare reserve selectors to be decision-*support* tools rather than decision-*making* tools, then evaluation functions used in optimization should reflect what it means for a solution or solution set to be optimal as decision support.  The current phrasing of optimality measures tacitly assume optimality is how well invidual solutions meet the cost and representation targets specified for them, independent of other solutions and of input uncertainty.  Instead, they should explicitly state and measure what it would mean for a single solution or a set of solutions to be optimal as decision advice.  For example, they could include things like:  
        - a measure of the *variety* in solutions produced (while still being decent individual solutions), or 
        - the measured *robustness* of solutions to relative problem difficulty and to uncertainty (of all kinds or specific kinds and amounts).

#  Software and data availability and reproducibility

All data and R source code [cite R team] for this paper are open source and available under the [xyz] license. The R code is at [github].  The data is at [someplace].

#  References

#  Supplementary Material

